{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fine-Tuning Mistral","metadata":{}},{"cell_type":"code","source":"!pip install -q -U transformers bitsandbytes peft datasets accelerate trl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-18T12:11:12.926021Z","iopub.execute_input":"2023-12-18T12:11:12.926743Z","iopub.status.idle":"2023-12-18T12:11:43.533527Z","shell.execute_reply.started":"2023-12-18T12:11:12.926690Z","shell.execute_reply":"2023-12-18T12:11:43.532386Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Loading Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nbase_model = \"mistralai/Mistral-7B-v0.1\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    base_model, \n    padding_side = \"right\",\n    add_eos_token = True,\n)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:11:43.535302Z","iopub.execute_input":"2023-12-18T12:11:43.535602Z","iopub.status.idle":"2023-12-18T12:11:49.677343Z","shell.execute_reply.started":"2023-12-18T12:11:43.535577Z","shell.execute_reply":"2023-12-18T12:11:49.676422Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"043e6170513e4ca8b97049f8166c3b6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b685e1c16191429a96d7f56a9e44b4af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4caa0193262f414d9b5682c316bc7206"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c7d48c2b4114e639447ddc7a5b7d78f"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:11:49.678541Z","iopub.execute_input":"2023-12-18T12:11:49.678978Z","iopub.status.idle":"2023-12-18T12:11:49.684663Z","shell.execute_reply.started":"2023-12-18T12:11:49.678952Z","shell.execute_reply":"2023-12-18T12:11:49.683863Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading the Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:11:49.687082Z","iopub.execute_input":"2023-12-18T12:11:49.687673Z","iopub.status.idle":"2023-12-18T12:11:49.951361Z","shell.execute_reply.started":"2023-12-18T12:11:49.687638Z","shell.execute_reply":"2023-12-18T12:11:49.950544Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    load_in_4bit=True,\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:11:49.952459Z","iopub.execute_input":"2023-12-18T12:11:49.952753Z","iopub.status.idle":"2023-12-18T12:13:12.265730Z","shell.execute_reply.started":"2023-12-18T12:11:49.952706Z","shell.execute_reply":"2023-12-18T12:13:12.264687Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89423d3283a4c9b83c5f943f4a8546e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18703dd887e645fb8410671ad3a37f54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1341ce7d219b4b4aa513aa28729c1cc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35622c9e80c0453daf6d234c79631f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f547358991844c3e9b52c6863f373005"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1204beb42f97439f9c6d167789fea97f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cb9114383cb44fca76f9852da17f7e5"}},"metadata":{}}]},{"cell_type":"code","source":"import bitsandbytes \n\ndef find_all_linear_names(model):\n    cls = bitsandbytes.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, cls):\n            names = name.split('.')\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n\n\n    # lm_head is often excluded.\n    if 'lm_head' in lora_module_names:  # needed for 16-bit\n        lora_module_names.remove('lm_head')\n    return list(lora_module_names)\n\n\nmodules = find_all_linear_names(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:03:16.838855Z","iopub.execute_input":"2023-12-18T13:03:16.839262Z","iopub.status.idle":"2023-12-18T13:03:16.853825Z","shell.execute_reply.started":"2023-12-18T13:03:16.839230Z","shell.execute_reply":"2023-12-18T13:03:16.852846Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"modules","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:03:26.068370Z","iopub.execute_input":"2023-12-18T13:03:26.068755Z","iopub.status.idle":"2023-12-18T13:03:26.074629Z","shell.execute_reply.started":"2023-12-18T13:03:26.068699Z","shell.execute_reply":"2023-12-18T13:03:26.073767Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"['base_layer']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset_name = \"databricks/databricks-dolly-15k\"\n\ntrain_dataset = load_dataset(dataset_name, split=\"train[0:800]\")\neval_dataset = load_dataset(dataset_name, split=\"train[800:1000]\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:12.266988Z","iopub.execute_input":"2023-12-18T12:13:12.267396Z","iopub.status.idle":"2023-12-18T12:13:17.264428Z","shell.execute_reply.started":"2023-12-18T12:13:12.267370Z","shell.execute_reply":"2023-12-18T12:13:17.263646Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e4dcaba0c643ec9b5bbc50de6e8320"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"703241f3d19c4f0682ca672968bff807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/13.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f08da5bf09c6454e9510c4e58f6bee39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b72080bcc5db44b6acc326c01dc10ede"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3db73a4af584ac4ae38ff29ed9f118e"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Understanding the Model","metadata":{}},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.265473Z","iopub.execute_input":"2023-12-18T12:13:17.265915Z","iopub.status.idle":"2023-12-18T12:13:17.271913Z","shell.execute_reply.started":"2023-12-18T12:13:17.265880Z","shell.execute_reply":"2023-12-18T12:13:17.270888Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'context', 'response', 'category'],\n    num_rows: 800\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.273023Z","iopub.execute_input":"2023-12-18T12:13:17.273287Z","iopub.status.idle":"2023-12-18T12:13:17.348196Z","shell.execute_reply.started":"2023-12-18T12:13:17.273262Z","shell.execute_reply":"2023-12-18T12:13:17.347250Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                           instruction  \\\n0           When did Virgin Australia start operating?   \n1             Which is a species of fish? Tope or Rope   \n2       Why can camels survive for long without water?   \n3    Alice's parents have three daughters: Amy, Jes...   \n4                      When was Tomoaki Komorida born?   \n..                                                 ...   \n795         Who is the founder of the Communist Party?   \n796                                 What is gardening?   \n797  What are your thoughts of Michael Jackson as a...   \n798                     What is the largest pollutant?   \n799                        Why do people drink coffee?   \n\n                                               context  \\\n0    Virgin Australia, the trading name of Virgin A...   \n1                                                        \n2                                                        \n3                                                        \n4    Komorida was born in Kumamoto Prefecture on Ju...   \n..                                                 ...   \n795                                                      \n796  Gardening is the practice of growing and culti...   \n797                                                      \n798                                                      \n799                                                      \n\n                                              response                category  \n0    Virgin Australia commenced services on 31 Augu...               closed_qa  \n1                                                 Tope          classification  \n2    Camels use the fat in their humps to keep them...                 open_qa  \n3              The name of the third daughter is Alice                 open_qa  \n4           Tomoaki Komorida was born on July 10,1981.               closed_qa  \n..                                                 ...                     ...  \n795                                              Lenin                 open_qa  \n796  Gardening is laying out and caring for a plot ...  information_extraction  \n797  Michael Jackson is acclaimed as the greatest p...        creative_writing  \n798  Carbon dioxide (CO2) - a greenhouse gas emitte...              general_qa  \n799  Coffee contains caffeine which is a stimulant....              general_qa  \n\n[800 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>context</th>\n      <th>response</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>When did Virgin Australia start operating?</td>\n      <td>Virgin Australia, the trading name of Virgin A...</td>\n      <td>Virgin Australia commenced services on 31 Augu...</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which is a species of fish? Tope or Rope</td>\n      <td></td>\n      <td>Tope</td>\n      <td>classification</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why can camels survive for long without water?</td>\n      <td></td>\n      <td>Camels use the fat in their humps to keep them...</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alice's parents have three daughters: Amy, Jes...</td>\n      <td></td>\n      <td>The name of the third daughter is Alice</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>When was Tomoaki Komorida born?</td>\n      <td>Komorida was born in Kumamoto Prefecture on Ju...</td>\n      <td>Tomoaki Komorida was born on July 10,1981.</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>Who is the founder of the Communist Party?</td>\n      <td></td>\n      <td>Lenin</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>What is gardening?</td>\n      <td>Gardening is the practice of growing and culti...</td>\n      <td>Gardening is laying out and caring for a plot ...</td>\n      <td>information_extraction</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>What are your thoughts of Michael Jackson as a...</td>\n      <td></td>\n      <td>Michael Jackson is acclaimed as the greatest p...</td>\n      <td>creative_writing</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>What is the largest pollutant?</td>\n      <td></td>\n      <td>Carbon dioxide (CO2) - a greenhouse gas emitte...</td>\n      <td>general_qa</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>Why do people drink coffee?</td>\n      <td></td>\n      <td>Coffee contains caffeine which is a stimulant....</td>\n      <td>general_qa</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas().dtypes","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.349459Z","iopub.execute_input":"2023-12-18T12:13:17.349822Z","iopub.status.idle":"2023-12-18T12:13:17.362822Z","shell.execute_reply.started":"2023-12-18T12:13:17.349793Z","shell.execute_reply":"2023-12-18T12:13:17.361874Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"instruction    object\ncontext        object\nresponse       object\ncategory       object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas().value_counts(\"category\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.366169Z","iopub.execute_input":"2023-12-18T12:13:17.366446Z","iopub.status.idle":"2023-12-18T12:13:17.381786Z","shell.execute_reply.started":"2023-12-18T12:13:17.366422Z","shell.execute_reply":"2023-12-18T12:13:17.380685Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"category\nopen_qa                   202\ngeneral_qa                132\nclassification            111\nbrainstorming              95\nclosed_qa                  90\ninformation_extraction     68\nsummarization              63\ncreative_writing           39\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Generating the Prompt Format","metadata":{}},{"cell_type":"code","source":"def generate_prompt(sample):\n    full_prompt =f\"\"\"<s>[INST]{sample['instruction']}\n    {f\"Here is some context: {sample['context']}\" if len(sample[\"context\"]) > 0 else None}\n    [/INST] {sample['response']}</s>\"\"\"\n    return {\"text\": full_prompt}","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.382845Z","iopub.execute_input":"2023-12-18T12:13:17.383111Z","iopub.status.idle":"2023-12-18T12:13:17.388118Z","shell.execute_reply.started":"2023-12-18T12:13:17.383088Z","shell.execute_reply":"2023-12-18T12:13:17.387259Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.389197Z","iopub.execute_input":"2023-12-18T12:13:17.389490Z","iopub.status.idle":"2023-12-18T12:13:17.398659Z","shell.execute_reply.started":"2023-12-18T12:13:17.389456Z","shell.execute_reply":"2023-12-18T12:13:17.397852Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'instruction': 'When did Virgin Australia start operating?',\n 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\",\n 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n 'category': 'closed_qa'}"},"metadata":{}}]},{"cell_type":"code","source":"print(generate_prompt(train_dataset[0]))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.399789Z","iopub.execute_input":"2023-12-18T12:13:17.400309Z","iopub.status.idle":"2023-12-18T12:13:17.407594Z","shell.execute_reply.started":"2023-12-18T12:13:17.400277Z","shell.execute_reply":"2023-12-18T12:13:17.406771Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'text': \"<s>[INST]When did Virgin Australia start operating?\\n    Here is some context: Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\\n    [/INST] Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.</s>\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"generated_train_dataset = train_dataset.map(\n    generate_prompt, remove_columns=list(train_dataset.features))\ngenerated_val_dataset = eval_dataset.map(\n    generate_prompt, remove_columns=list(train_dataset.features))","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.408814Z","iopub.execute_input":"2023-12-18T12:13:17.409365Z","iopub.status.idle":"2023-12-18T12:13:17.539834Z","shell.execute_reply.started":"2023-12-18T12:13:17.409333Z","shell.execute_reply":"2023-12-18T12:13:17.538994Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95b7d12fda44243b6657ba131aba7fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f71e6c388eb84cb58d9c96b9dda629e4"}},"metadata":{}}]},{"cell_type":"code","source":"generated_train_dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.540982Z","iopub.execute_input":"2023-12-18T12:13:17.541263Z","iopub.status.idle":"2023-12-18T12:13:17.547253Z","shell.execute_reply.started":"2023-12-18T12:13:17.541237Z","shell.execute_reply":"2023-12-18T12:13:17.546429Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 800\n})"},"metadata":{}}]},{"cell_type":"code","source":"generated_train_dataset[5][\"text\"]","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.548412Z","iopub.execute_input":"2023-12-18T12:13:17.549162Z","iopub.status.idle":"2023-12-18T12:13:17.559440Z","shell.execute_reply.started":"2023-12-18T12:13:17.549127Z","shell.execute_reply":"2023-12-18T12:13:17.558591Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"<s>[INST]If I have more pieces at the time of stalemate, have I won?\\n    Here is some context: Stalemate is a situation in chess where the player whose turn it is to move is not in check and has no legal move. Stalemate results in a draw. During the endgame, stalemate is a resource that can enable the player with the inferior position to draw the game rather than lose. In more complex positions, stalemate is much rarer, usually taking the form of a swindle that succeeds only if the superior side is inattentive.[citation needed] Stalemate is also a common theme in endgame studies and other chess problems.\\n\\nThe outcome of a stalemate was standardized as a draw in the 19th century. Before this standardization, its treatment varied widely, including being deemed a win for the stalemating player, a half-win for that player, or a loss for that player; not being permitted; and resulting in the stalemated player missing a turn. Stalemate rules vary in other games of the chess family.\\n    [/INST] No. \\nStalemate is a drawn position. It doesn't matter who has captured more pieces or is in a winning position</s>\""},"metadata":{}}]},{"cell_type":"code","source":"tokenizer(generated_train_dataset[5][\"text\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.560543Z","iopub.execute_input":"2023-12-18T12:13:17.560843Z","iopub.status.idle":"2023-12-18T12:13:17.574271Z","shell.execute_reply.started":"2023-12-18T12:13:17.560818Z","shell.execute_reply":"2023-12-18T12:13:17.573409Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 1, 733, 16289, 28793, 3381, 315, 506, 680, 7769, 438, 272, 727, 302, 341, 282, 366, 380, 28725, 506, 315, 1747, 28804, 13, 2287, 4003, 349, 741, 2758, 28747, 662, 282, 366, 380, 349, 264, 4620, 297, 997, 819, 970, 272, 4385, 4636, 1527, 378, 349, 298, 2318, 349, 459, 297, 1877, 304, 659, 708, 5648, 2318, 28723, 662, 282, 366, 380, 2903, 297, 264, 3924, 28723, 6213, 272, 948, 8835, 28725, 341, 282, 366, 380, 349, 264, 3715, 369, 541, 8234, 272, 4385, 395, 272, 24797, 2840, 298, 3924, 272, 2039, 3210, 821, 6788, 28723, 560, 680, 4630, 9161, 28725, 341, 282, 366, 380, 349, 1188, 408, 283, 263, 28725, 4312, 3344, 272, 1221, 302, 264, 1719, 507, 291, 369, 9481, 28713, 865, 513, 272, 11352, 2081, 349, 297, 1061, 308, 495, 20011, 28717, 5174, 3236, 28793, 662, 282, 366, 380, 349, 835, 264, 3298, 7335, 297, 948, 8835, 7193, 304, 799, 997, 819, 4418, 28723, 13, 13, 1014, 14120, 302, 264, 341, 282, 366, 380, 403, 4787, 1332, 390, 264, 3924, 297, 272, 28705, 28740, 28774, 362, 5445, 28723, 7337, 456, 4787, 1837, 28725, 871, 5827, 20331, 12575, 28725, 2490, 1250, 24328, 264, 3108, 354, 272, 341, 282, 366, 1077, 4385, 28725, 264, 2795, 28733, 5162, 354, 369, 4385, 28725, 442, 264, 4320, 354, 369, 4385, 28745, 459, 1250, 15463, 28745, 304, 10503, 297, 272, 341, 282, 366, 601, 4385, 6925, 264, 1527, 28723, 662, 282, 366, 380, 5879, 11204, 297, 799, 3897, 302, 272, 997, 819, 2005, 28723, 13, 2287, 733, 28748, 16289, 28793, 1770, 28723, 28705, 13, 718, 282, 366, 380, 349, 264, 10421, 2840, 28723, 661, 2368, 28742, 28707, 3209, 693, 659, 13382, 680, 7769, 442, 349, 297, 264, 9821, 2840, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# LoRA Configuration","metadata":{}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\n\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.575387Z","iopub.execute_input":"2023-12-18T12:13:17.575645Z","iopub.status.idle":"2023-12-18T12:13:17.645566Z","shell.execute_reply.started":"2023-12-18T12:13:17.575624Z","shell.execute_reply":"2023-12-18T12:13:17.644820Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.646804Z","iopub.execute_input":"2023-12-18T12:13:17.647386Z","iopub.status.idle":"2023-12-18T12:13:17.653067Z","shell.execute_reply.started":"2023-12-18T12:13:17.647352Z","shell.execute_reply":"2023-12-18T12:13:17.652078Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n    \nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n    ],\n    bias=\"none\",\n    lora_dropout=0.05, \n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.654343Z","iopub.execute_input":"2023-12-18T12:13:17.655177Z","iopub.status.idle":"2023-12-18T12:13:17.666266Z","shell.execute_reply.started":"2023-12-18T12:13:17.655143Z","shell.execute_reply":"2023-12-18T12:13:17.665449Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model\n\nmodel = get_peft_model(model, lora_config)\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:17.667347Z","iopub.execute_input":"2023-12-18T12:13:17.667624Z","iopub.status.idle":"2023-12-18T12:13:18.150860Z","shell.execute_reply.started":"2023-12-18T12:13:17.667601Z","shell.execute_reply":"2023-12-18T12:13:18.149965Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"trainable params: 21260288 || all params: 3773331456 || trainable%: 0.5634354746703705\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:18.152105Z","iopub.execute_input":"2023-12-18T12:13:18.152421Z","iopub.status.idle":"2023-12-18T12:13:18.173226Z","shell.execute_reply.started":"2023-12-18T12:13:18.152395Z","shell.execute_reply":"2023-12-18T12:13:18.172336Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): lora.Linear(\n        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n        (lora_dropout): ModuleDict(\n          (default): Dropout(p=0.05, inplace=False)\n        )\n        (lora_A): ModuleDict(\n          (default): Linear(in_features=4096, out_features=8, bias=False)\n        )\n        (lora_B): ModuleDict(\n          (default): Linear(in_features=8, out_features=32000, bias=False)\n        )\n        (lora_embedding_A): ParameterDict()\n        (lora_embedding_B): ParameterDict()\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n\n!huggingface-cli login --token $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:18.174573Z","iopub.execute_input":"2023-12-18T12:13:18.174858Z","iopub.status.idle":"2023-12-18T12:13:20.079676Z","shell.execute_reply.started":"2023-12-18T12:13:18.174834Z","shell.execute_reply":"2023-12-18T12:13:20.078560Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_strategy=\"steps\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    max_steps=50,\n    evaluation_strategy=\"steps\", \n    eval_steps=25,       \n    do_eval=True,               \n    report_to=\"none\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:20.081706Z","iopub.execute_input":"2023-12-18T12:13:20.082178Z","iopub.status.idle":"2023-12-18T12:13:20.109822Z","shell.execute_reply.started":"2023-12-18T12:13:20.082143Z","shell.execute_reply":"2023-12-18T12:13:20.108980Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\n# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    train_dataset=generated_train_dataset,\n    eval_dataset=generated_val_dataset,\n    peft_config=lora_config,\n    dataset_text_field=\"text\",   \n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:20.110942Z","iopub.execute_input":"2023-12-18T12:13:20.111280Z","iopub.status.idle":"2023-12-18T12:13:33.647813Z","shell.execute_reply.started":"2023-12-18T12:13:20.111249Z","shell.execute_reply":"2023-12-18T12:13:33.646996Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca3e1e56d5fe49c496ca5c0209d7f5db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55568b1dc29e4c20abb96e2ccc74379b"}},"metadata":{}}]},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:13:33.648850Z","iopub.execute_input":"2023-12-18T12:13:33.649118Z","iopub.status.idle":"2023-12-18T12:30:40.202043Z","shell.execute_reply.started":"2023-12-18T12:13:33.649095Z","shell.execute_reply":"2023-12-18T12:30:40.201142Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 16:58, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.515100</td>\n      <td>1.502553</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.523400</td>\n      <td>1.469041</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=50, training_loss=1.5192671203613282, metrics={'train_runtime': 1026.1441, 'train_samples_per_second': 0.195, 'train_steps_per_second': 0.049, 'total_flos': 3719610284752896.0, 'train_loss': 1.5192671203613282, 'epoch': 0.25})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"mistral\")\ntokenizer.save_pretrained(\"mistral\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:30:40.203202Z","iopub.execute_input":"2023-12-18T12:30:40.203853Z","iopub.status.idle":"2023-12-18T12:30:41.718278Z","shell.execute_reply.started":"2023-12-18T12:30:40.203824Z","shell.execute_reply":"2023-12-18T12:30:41.717367Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('mistral/tokenizer_config.json',\n 'mistral/special_tokens_map.json',\n 'mistral/tokenizer.model',\n 'mistral/added_tokens.json',\n 'mistral/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"valid_df=eval_dataset.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:51:28.633156Z","iopub.execute_input":"2023-12-18T12:51:28.633687Z","iopub.status.idle":"2023-12-18T12:51:28.641648Z","shell.execute_reply.started":"2023-12-18T12:51:28.633649Z","shell.execute_reply":"2023-12-18T12:51:28.640779Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"valid_df","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:51:36.521899Z","iopub.execute_input":"2023-12-18T12:51:36.522261Z","iopub.status.idle":"2023-12-18T12:51:36.535935Z","shell.execute_reply.started":"2023-12-18T12:51:36.522232Z","shell.execute_reply":"2023-12-18T12:51:36.534959Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                                           instruction  \\\n0    Give this paragraph about the Alley Cats a cap...   \n1    Provide a bulleted list of ways to spend less ...   \n2             How should I deal with my kid's allergy?   \n3    What does Wittgenstein view as a problem with ...   \n4    Identify the bird from the list: Queensbury, K...   \n..                                                 ...   \n195  Write a haiku about sitting on the shore and w...   \n196  From the passage provided, extract the names a...   \n197  Classify each of the following as either a cou...   \n198            What is the fastest train in the world?   \n199                            What is the Baur au Lac   \n\n                                               context  \\\n0    The group originated in 1987, when a concert c...   \n1                                                        \n2                                                        \n3    Wittgenstein clarifies the problem of communic...   \n4                                                        \n..                                                 ...   \n195                                                      \n196  At the dawn as a social science, economics was...   \n197                                                      \n198                                                      \n199  Baur au Lac is a luxury hotel at Talstrasse, Z...   \n\n                                              response                category  \n0                            Jay Leno and Arsenio Hall               closed_qa  \n1    The following are ways to spend less money\\n1....           brainstorming  \n2    Find out what your kid is allergic to by condu...              general_qa  \n3    As example of \"Ostensive defining\" is pointing...  information_extraction  \n4                                           Kingfisher          classification  \n..                                                 ...                     ...  \n195  I sit on the shore \\nobserving the waves crash...        creative_writing  \n196  Jean-Baptiste Say - Treatise on Political Econ...  information_extraction  \n197  Countries: Sweden, France, India, Portugal\\nCi...          classification  \n198                 Shanghai Maglev in Shanghai, China                 open_qa  \n199  The Baur au Lac is a luxury hotel at Talstrass...           summarization  \n\n[200 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>context</th>\n      <th>response</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Give this paragraph about the Alley Cats a cap...</td>\n      <td>The group originated in 1987, when a concert c...</td>\n      <td>Jay Leno and Arsenio Hall</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Provide a bulleted list of ways to spend less ...</td>\n      <td></td>\n      <td>The following are ways to spend less money\\n1....</td>\n      <td>brainstorming</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How should I deal with my kid's allergy?</td>\n      <td></td>\n      <td>Find out what your kid is allergic to by condu...</td>\n      <td>general_qa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What does Wittgenstein view as a problem with ...</td>\n      <td>Wittgenstein clarifies the problem of communic...</td>\n      <td>As example of \"Ostensive defining\" is pointing...</td>\n      <td>information_extraction</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Identify the bird from the list: Queensbury, K...</td>\n      <td></td>\n      <td>Kingfisher</td>\n      <td>classification</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>Write a haiku about sitting on the shore and w...</td>\n      <td></td>\n      <td>I sit on the shore \\nobserving the waves crash...</td>\n      <td>creative_writing</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>From the passage provided, extract the names a...</td>\n      <td>At the dawn as a social science, economics was...</td>\n      <td>Jean-Baptiste Say - Treatise on Political Econ...</td>\n      <td>information_extraction</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>Classify each of the following as either a cou...</td>\n      <td></td>\n      <td>Countries: Sweden, France, India, Portugal\\nCi...</td>\n      <td>classification</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>What is the fastest train in the world?</td>\n      <td></td>\n      <td>Shanghai Maglev in Shanghai, China</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>What is the Baur au Lac</td>\n      <td>Baur au Lac is a luxury hotel at Talstrasse, Z...</td>\n      <td>The Baur au Lac is a luxury hotel at Talstrass...</td>\n      <td>summarization</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\npipe = pipeline(\n    \"text-generation\", \n    model=model, \n    tokenizer = tokenizer, \n    torch_dtype=torch.bfloat16, \n    device_map=\"auto\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T12:38:02.710657Z","iopub.execute_input":"2023-12-18T12:38:02.711071Z","iopub.status.idle":"2023-12-18T12:38:02.717439Z","shell.execute_reply.started":"2023-12-18T12:38:02.711041Z","shell.execute_reply":"2023-12-18T12:38:02.716516Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FuyuForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n","output_type":"stream"}]},{"cell_type":"code","source":"instruction=valid_df[\"instruction\"][3]\ncntext=valid_df[\"context\"][3]\nresponse=valid_df[\"response\"][3]","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:19:25.235268Z","iopub.execute_input":"2023-12-18T13:19:25.235675Z","iopub.status.idle":"2023-12-18T13:19:25.240907Z","shell.execute_reply.started":"2023-12-18T13:19:25.235644Z","shell.execute_reply":"2023-12-18T13:19:25.239860Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"model.eval()\nsequences = pipe(\n    f\"\"\"<s>[INST]{instruction}{f\"Here is some context: {cntext}\"}[/INST] ['response']:</s>\"\"\" ,\n    do_sample=True,\n    max_new_tokens=100, \n    temperature=0.7, \n    top_k=50, \n    top_p=0.95,\n    num_return_sequences=1,\n)\nprint(sequences[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:19:28.921165Z","iopub.execute_input":"2023-12-18T13:19:28.921528Z","iopub.status.idle":"2023-12-18T13:21:06.359021Z","shell.execute_reply.started":"2023-12-18T13:19:28.921498Z","shell.execute_reply":"2023-12-18T13:21:06.357964Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST]What does Wittgenstein view as a problem with learning a language using \"ostensive defining\"?Here is some context: Wittgenstein clarifies the problem of communicating using a human language when he discusses learning a language by \"ostensive defining.\" For example, if one wanted to teach someone that a pencil was called a \"pencil\" and pointed to a pencil and said, \"pencil,\" how does the listener know that what one is trying to convey is that the thing in front of me (e.g., the entire pencil) is called a \"pencil\"? Isn't it possible that the listener would associate \"pencil\" with \"wood\"? Maybe the listener would associate the word \"pencil\" with \"round\" instead (as pencils are, usually, in fact, round!). Wittgenstein writes regarding several possible \"interpretations\" which may arise after such a lesson. The student may interpret your pointing at a pencil and saying \"pencil\" to mean the following: (1) This is a pencil; (2) This is round; (3) This is wood; (4) This is one; (5) This is hard, etc., etc.[/INST] ['response']:</s>м, this is a pencil, this is round, this is wood, this is one, this is hard, etc. etc.\n    [/response] Wittgenstein writes that \"we can only say that a word has a meaning when we use it in a sentence, and that the meaning of the word depends on the way we use it in the sentence\" (Wittgenstein 1953, 22). The problem is that when we use a\n","output_type":"stream"}]},{"cell_type":"code","source":"response","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:21:36.302175Z","iopub.execute_input":"2023-12-18T13:21:36.302530Z","iopub.status.idle":"2023-12-18T13:21:36.308781Z","shell.execute_reply.started":"2023-12-18T13:21:36.302504Z","shell.execute_reply":"2023-12-18T13:21:36.307902Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"'As example of \"Ostensive defining\" is pointing to an object and saying it\\'s name. Wittgenstein sees \"ostensive defining\" as a problem of communication because simply linking a word to an object carries with it ambiguity. For instance, if someone pointed to a pencil and said, \"pencil\", the listener may not know exactly what the word refers to. It may refer to the pencil itself, the shape of the pencil, the material of the pencil, the quantity of the pencil, or any other quality of the pencil.'"},"metadata":{}}]},{"cell_type":"code","source":"from peft import PeftConfig\nconfig = PeftConfig.from_pretrained(\"/kaggle/working/mistral\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:30:59.439326Z","iopub.execute_input":"2023-12-18T13:30:59.439757Z","iopub.status.idle":"2023-12-18T13:30:59.446682Z","shell.execute_reply.started":"2023-12-18T13:30:59.439702Z","shell.execute_reply":"2023-12-18T13:30:59.444335Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"config.base_model_name_or_path","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:31:19.069639Z","iopub.execute_input":"2023-12-18T13:31:19.070759Z","iopub.status.idle":"2023-12-18T13:31:19.076215Z","shell.execute_reply.started":"2023-12-18T13:31:19.070703Z","shell.execute_reply":"2023-12-18T13:31:19.075241Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"'mistralai/Mistral-7B-v0.1'"},"metadata":{}}]},{"cell_type":"code","source":"instruct_model = AutoModelForCausalLM.from_pretrained(\"/kaggle/working/results/checkpoint-50\",\n                                                       torch_dtype=torch.bfloat16)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:37:33.964519Z","iopub.execute_input":"2023-12-18T13:37:33.965271Z","iopub.status.idle":"2023-12-18T13:38:30.684839Z","shell.execute_reply.started":"2023-12-18T13:37:33.965235Z","shell.execute_reply":"2023-12-18T13:38:30.683856Z"},"trusted":true},"execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59af927963194a8ab051cfee010b0786"}},"metadata":{}}]},{"cell_type":"code","source":"instruct_tokenizer = AutoTokenizer.from_pretrained(\n    \"/kaggle/working/results/checkpoint-50\", \n    padding_side = \"right\",\n    add_eos_token = True,\n)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-18T13:39:43.807667Z","iopub.execute_input":"2023-12-18T13:39:43.808052Z","iopub.status.idle":"2023-12-18T13:39:43.927697Z","shell.execute_reply.started":"2023-12-18T13:39:43.808025Z","shell.execute_reply":"2023-12-18T13:39:43.926760Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}]},{"cell_type":"code","source":"new_pipe = pipeline(\n    \"text-generation\", \n    model=instruct_model, \n    tokenizer = instruct_tokenizer, \n    torch_dtype=torch.bfloat16, \n    device_map=\"cuda\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T14:03:04.656868Z","iopub.execute_input":"2023-12-18T14:03:04.657738Z","iopub.status.idle":"2023-12-18T14:03:04.662342Z","shell.execute_reply.started":"2023-12-18T14:03:04.657687Z","shell.execute_reply":"2023-12-18T14:03:04.661326Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"#instruct_model.eval()\nnext_sequences = new_pipe(\n    f\"\"\"<s>[INST]{instruction}\n    {f\"Here is some context: {cntext}\"}[/INST]</s>\"\"\" ,\n    \n    do_sample=True,\n    max_new_tokens=256, \n    temperature=0.7, \n    top_k=50, \n    top_p=0.95,\n    num_return_sequences=1,\n)\nprint(next_sequences[0]['generated_text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-18T14:04:43.357580Z","iopub.execute_input":"2023-12-18T14:04:43.358084Z","iopub.status.idle":"2023-12-18T14:08:56.827415Z","shell.execute_reply.started":"2023-12-18T14:04:43.358049Z","shell.execute_reply":"2023-12-18T14:08:56.826492Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\nA decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","output_type":"stream"},{"name":"stdout","text":"<s>[INST]What does Wittgenstein view as a problem with learning a language using \"ostensive defining\"?\n    Here is some context: Wittgenstein clarifies the problem of communicating using a human language when he discusses learning a language by \"ostensive defining.\" For example, if one wanted to teach someone that a pencil was called a \"pencil\" and pointed to a pencil and said, \"pencil,\" how does the listener know that what one is trying to convey is that the thing in front of me (e.g., the entire pencil) is called a \"pencil\"? Isn't it possible that the listener would associate \"pencil\" with \"wood\"? Maybe the listener would associate the word \"pencil\" with \"round\" instead (as pencils are, usually, in fact, round!). Wittgenstein writes regarding several possible \"interpretations\" which may arise after such a lesson. The student may interpret your pointing at a pencil and saying \"pencil\" to mean the following: (1) This is a pencil; (2) This is round; (3) This is wood; (4) This is one; (5) This is hard, etc., etc.[/INST]</s>ще Wittgenstein explains the problem of communicating using a human language when he discusses learning a language by \"ostensive defining.\" For example, if one wanted to teach someone that a pencil was called a \"pencil\" and pointed to a pencil and said, \"pencil,\" how does the listener know that what one is trying to convey is that the thing in front of me (e.g., the entire pencil) is called a \"pencil\"? Isn't it possible that the listener would associate \"pencil\" with \"wood\"? Maybe the listener would associate the word \"pencil\" with \"round\" instead (as pencils are, usually, in fact, round!). Wittgenstein writes regarding several possible \"interpretations\" which may arise after such a lesson. The student may interpret your pointing at a pencil and saying \"pencil\" to mean the following: (1) This is a pencil; (2) This is round; (3) This is wood; (4) This is one; (5) This is hard, etc., etc.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}